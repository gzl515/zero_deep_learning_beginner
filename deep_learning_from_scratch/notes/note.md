# 深度学习入门：基于python的理论与实践 - 读书总结

## 基础知识打底
学习深度学习需要准备的一些基础知识（不需要太深入即可理解代码）：
- [Python](https://www.python.org/)：编程语言
- [Numpy](https://numpy.org/)：做一些数据计算
- [Matplotlib](https://matplotlib.org/)：绘制图形，可视化数据结果做分析
- 一些基础数学：线性代数，概率论，微积分等，会一些基础更容易理解深度学习模型意义

## 引题

对于式子 y = w1 * x1 + w2 * x2 + b：
1. 假设我们确定 x1 = 2，x2 = 3，y = 7，那么 w1、w2、b 分别等于几的时候等式成立？
2. 假设有一组数据：
   ```python
   X = [
   	[2, 3],
   	[5, 7],
   	[1, 9],
   ]
   Y = [6,2,5]
   ```
如果要满足 Y = X * W + B，那么 W、B 应该是多少？

让我们先保留这个疑问。

## 神经网络
神经网络就是通过建立一个网络模型，例如上述 Y = X * W + B，让模型根据大量的数据 X 和结果 Y，去找到一个合适的 W 和 B，计算出 Y_ = X * W + B。
为什么是 Y_ 呢？因为由于数据量的原因，总不会有一组数据 W 和 B 计算出来的结果完全等于 Y。
所有一个好的模型能做到的就是让 (Y - Y_) 尽量的小，也就是结果接近准确。

学习是确定合适的参数的过程，而人要做的就是思考模型，并把训练数据交给计算机，让计算机去学习。

## 网络结构总结
- Affine层
- 激活函数层
  - sigmoid函数
  - ReLU函数
- 根据网络层数重复【Affine层】和【激活函数层】
- 激活函数层
  - softmax函数
- 损失函数
  - 均方误差
  - 交叉熵误差

## 知识点总结
- 激活函数的作用
  - sigmoid函数
  - ReLU函数
  - softmax函数
- 损失函数
- 正向传播
- 梯度下降
- 中值微分
- 误差反向传播
  1. mini-batch
  2. 计算梯度
  3. 更新参数
  4. 重复123

- 优化
  - w值初始值
  - 当激活值分布不均时，使用Batch Normalization
  - 解决过拟合
    - 权值衰减
    - Dropout
    - 超参数的验证
- 加深网络层的作用
  1. 可以减少网络的参数数量
  2. 是学习更加高效

## 存在的疑问
1. 为什么误差反向传播法比中值微分快？
2. sogmoid和ReLU怎么选？
3. 损失函数怎么选？
